{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alvar\\miniconda3\\envs\\mentor-eval-datasets\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mohler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2273, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mohler_rote= r\"C:\\Users\\alvar\\Desktop\\mohler_dataset_edited.csv\"\n",
    "\n",
    "df = pd.read_csv(mohler_rote)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>desired_answer</th>\n",
       "      <th>student_answer</th>\n",
       "      <th>score_me</th>\n",
       "      <th>score_other</th>\n",
       "      <th>score_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>What is the role of a prototype program in pro...</td>\n",
       "      <td>To simulate the behaviour of portions of the d...</td>\n",
       "      <td>High risk problems are address in the prototyp...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>What is the role of a prototype program in pro...</td>\n",
       "      <td>To simulate the behaviour of portions of the d...</td>\n",
       "      <td>To simulate portions of the desired final prod...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1</td>\n",
       "      <td>What is the role of a prototype program in pro...</td>\n",
       "      <td>To simulate the behaviour of portions of the d...</td>\n",
       "      <td>A prototype program simulates the behaviors of...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1</td>\n",
       "      <td>What is the role of a prototype program in pro...</td>\n",
       "      <td>To simulate the behaviour of portions of the d...</td>\n",
       "      <td>Defined in the Specification phase a prototype...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1</td>\n",
       "      <td>What is the role of a prototype program in pro...</td>\n",
       "      <td>To simulate the behaviour of portions of the d...</td>\n",
       "      <td>It is used to let the users have a first idea ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                           question  \\\n",
       "0  1.1  What is the role of a prototype program in pro...   \n",
       "1  1.1  What is the role of a prototype program in pro...   \n",
       "2  1.1  What is the role of a prototype program in pro...   \n",
       "3  1.1  What is the role of a prototype program in pro...   \n",
       "4  1.1  What is the role of a prototype program in pro...   \n",
       "\n",
       "                                      desired_answer  \\\n",
       "0  To simulate the behaviour of portions of the d...   \n",
       "1  To simulate the behaviour of portions of the d...   \n",
       "2  To simulate the behaviour of portions of the d...   \n",
       "3  To simulate the behaviour of portions of the d...   \n",
       "4  To simulate the behaviour of portions of the d...   \n",
       "\n",
       "                                      student_answer  score_me  score_other  \\\n",
       "0  High risk problems are address in the prototyp...       4.0          3.0   \n",
       "1  To simulate portions of the desired final prod...       5.0          5.0   \n",
       "2  A prototype program simulates the behaviors of...       5.0          3.0   \n",
       "3  Defined in the Specification phase a prototype...       5.0          5.0   \n",
       "4  It is used to let the users have a first idea ...       3.0          3.0   \n",
       "\n",
       "   score_avg  \n",
       "0        3.5  \n",
       "1        5.0  \n",
       "2        4.0  \n",
       "3        5.0  \n",
       "4        3.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASAP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24728, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asap2_path = r\"C:\\Users\\alvar\\Githubs\\mentor-eval\\datasets\\asap2\\ASAP2_train_sourcetexts.csv\"\n",
    "asap2_df = pd.read_csv(asap2_path)\n",
    "\n",
    "asap2_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>score</th>\n",
       "      <th>full_text</th>\n",
       "      <th>assignment</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>economically_disadvantaged</th>\n",
       "      <th>student_disability_status</th>\n",
       "      <th>ell_status</th>\n",
       "      <th>race_ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>source_text_1</th>\n",
       "      <th>source_text_2</th>\n",
       "      <th>source_text_3</th>\n",
       "      <th>source_text_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAVUP14319000159574</td>\n",
       "      <td>4</td>\n",
       "      <td>The author suggests that studying Venus is wor...</td>\n",
       "      <td>In \"The Challenge of Exploring Venus,\" the aut...</td>\n",
       "      <td>Exploring Venus</td>\n",
       "      <td>Economically disadvantaged</td>\n",
       "      <td>Identified as having disability</td>\n",
       "      <td>No</td>\n",
       "      <td>Black/African American</td>\n",
       "      <td>F</td>\n",
       "      <td>The Challenge of Exploring Venus\\nVenus, somet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAVUP14319000159542</td>\n",
       "      <td>2</td>\n",
       "      <td>NASA is fighting to be alble to to go to Venus...</td>\n",
       "      <td>In \"The Challenge of Exploring Venus,\" the aut...</td>\n",
       "      <td>Exploring Venus</td>\n",
       "      <td>Not economically disadvantaged</td>\n",
       "      <td>Not identified as having disability</td>\n",
       "      <td>No</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>F</td>\n",
       "      <td>The Challenge of Exploring Venus\\nVenus, somet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAVUP14319000159461</td>\n",
       "      <td>3</td>\n",
       "      <td>\"The Evening Star\", is one of the brightest po...</td>\n",
       "      <td>In \"The Challenge of Exploring Venus,\" the aut...</td>\n",
       "      <td>Exploring Venus</td>\n",
       "      <td>Economically disadvantaged</td>\n",
       "      <td>Identified as having disability</td>\n",
       "      <td>No</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>The Challenge of Exploring Venus\\nVenus, somet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAVUP14319000159420</td>\n",
       "      <td>2</td>\n",
       "      <td>The author supports this idea because from rea...</td>\n",
       "      <td>In \"The Challenge of Exploring Venus,\" the aut...</td>\n",
       "      <td>Exploring Venus</td>\n",
       "      <td>Economically disadvantaged</td>\n",
       "      <td>Not identified as having disability</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>F</td>\n",
       "      <td>The Challenge of Exploring Venus\\nVenus, somet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAVUP14319000159419</td>\n",
       "      <td>2</td>\n",
       "      <td>How the author supports this idea is that he s...</td>\n",
       "      <td>In \"The Challenge of Exploring Venus,\" the aut...</td>\n",
       "      <td>Exploring Venus</td>\n",
       "      <td>Economically disadvantaged</td>\n",
       "      <td>Not identified as having disability</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>M</td>\n",
       "      <td>The Challenge of Exploring Venus\\nVenus, somet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               essay_id  score  \\\n",
       "0  AAAVUP14319000159574      4   \n",
       "1  AAAVUP14319000159542      2   \n",
       "2  AAAVUP14319000159461      3   \n",
       "3  AAAVUP14319000159420      2   \n",
       "4  AAAVUP14319000159419      2   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  The author suggests that studying Venus is wor...   \n",
       "1  NASA is fighting to be alble to to go to Venus...   \n",
       "2  \"The Evening Star\", is one of the brightest po...   \n",
       "3  The author supports this idea because from rea...   \n",
       "4  How the author supports this idea is that he s...   \n",
       "\n",
       "                                          assignment      prompt_name  \\\n",
       "0  In \"The Challenge of Exploring Venus,\" the aut...  Exploring Venus   \n",
       "1  In \"The Challenge of Exploring Venus,\" the aut...  Exploring Venus   \n",
       "2  In \"The Challenge of Exploring Venus,\" the aut...  Exploring Venus   \n",
       "3  In \"The Challenge of Exploring Venus,\" the aut...  Exploring Venus   \n",
       "4  In \"The Challenge of Exploring Venus,\" the aut...  Exploring Venus   \n",
       "\n",
       "       economically_disadvantaged            student_disability_status  \\\n",
       "0      Economically disadvantaged      Identified as having disability   \n",
       "1  Not economically disadvantaged  Not identified as having disability   \n",
       "2      Economically disadvantaged      Identified as having disability   \n",
       "3      Economically disadvantaged  Not identified as having disability   \n",
       "4      Economically disadvantaged  Not identified as having disability   \n",
       "\n",
       "  ell_status          race_ethnicity gender  \\\n",
       "0         No  Black/African American      F   \n",
       "1         No         Hispanic/Latino      F   \n",
       "2         No                   White      M   \n",
       "3        Yes         Hispanic/Latino      F   \n",
       "4        Yes         Hispanic/Latino      M   \n",
       "\n",
       "                                       source_text_1 source_text_2  \\\n",
       "0  The Challenge of Exploring Venus\\nVenus, somet...           NaN   \n",
       "1  The Challenge of Exploring Venus\\nVenus, somet...           NaN   \n",
       "2  The Challenge of Exploring Venus\\nVenus, somet...           NaN   \n",
       "3  The Challenge of Exploring Venus\\nVenus, somet...           NaN   \n",
       "4  The Challenge of Exploring Venus\\nVenus, somet...           NaN   \n",
       "\n",
       "  source_text_3 source_text_4  \n",
       "0           NaN           NaN  \n",
       "1           NaN           NaN  \n",
       "2           NaN           NaN  \n",
       "3           NaN           NaN  \n",
       "4           NaN           NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asap2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assignment\n",
       "In the article “Driverless Cars are Coming,” the author presents both positive and negative aspects of driverless cars. Using details from the article, create an argument for or against the development of these cars.  Be sure to include: your position on driverless cars; appropriate details from the article that support your position; an introduction, a body, and a conclusion to your argumentative essay.                                                                                                                                                                                                   6170\n",
       "In the article \"Making Mona Lisa Smile,\" the author describes how a new technology called the Facial Action Coding System enables computers to identify human emotions. Using details from the article, write an essay arguing whether the use of this technology to read the emotional expressions of students in a classroom is valuable.                                                                                                                                                                                                                                                                               4883\n",
       "In \"The Challenge of Exploring Venus,\" the author suggests studying Venus is a worthy pursuit despite the dangers it presents. Using details from the article, write an essay evaluating how well the author supports this idea. Be sure to include: a claim that evaluates how well the author supports the idea that studying Venus is a worthy pursuit despite the dangers; an explanation of the evidence from the article that supports your claim; an introduction, a body, and a conclusion to your essay.                                                                                                         4480\n",
       "You have read the article 'Unmasking the Face on Mars.' Imagine you are a scientist at NASA discussing the Face with someone who thinks it was created by aliens. Using information in the article, write an argumentative essay to convince someone that the Face is just a natural landform.Be sure to include: claims to support your argument that the Face is a natural landform; evidence from the article to support your claims; an introduction, a body, and a conclusion to your argumentative essay.                                                                                                           3015\n",
       "You have just read the article, 'A Cowboy Who Rode the Waves.' Luke's participation in the Seagoing Cowboys program allowed him to experience adventures and visit many unique places. Using information from the article, write an argument from Luke's point of view convincing others to participate in the Seagoing Cowboys program. Be sure to include: reasons to join the program; details from the article to support Luke's claims; an introduction, a body, and a conclusion to your essay.                                                                                                                     2175\n",
       "Write a letter to your state senator in which you argue in favor of keeping the Electoral College or changing to election by popular vote for the president of the United States. Use the information from the texts in your essay. Manage your time carefully so that you can read the passages; plan your response; write your response; and revise and edit your response. Be sure to include a claim; address counterclaims; use evidence from multiple sources; and avoid overly relying on one source. Your response should be in the form of a multiparagraph essay. Write your response in the space provided.    2046\n",
       "Write an explanatory essay to inform fellow citizens about the advantages of limiting car usage. Your essay must be based on ideas and information that can be found in the passage set. Manage your time carefully so that you can read the passages; plan your response; write your response; and revise and edit your response. Be sure to use evidence from multiple sources; and avoid overly relying on one source. Your response should be in the form of a multiparagraph essay. Write your essay in the space provided.                                                                                          1959\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asap2_df['assignment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- essay_id: AAAVUP14319000155922\n",
      "- score: 3\n",
      "- full_text: They want people to go study in Venus but it is a darngeous planet. is it even woth to risk their lives on this mission. But their i many sloution to that problem. Thesis :The problem studying a venus is the risk, dranger, tempeature but should not should not stop us.\n",
      "\n",
      "In the Article \"The Challenge of Exploring Venus\" reported Venus is dangerous becuase they sent a spacecarft to space. Not many people surivied\n",
      "\n",
      "died in a few hour. In a lifetime no one has been able to land on life time. Venus it is a very hot planet include Powerful earthquakes and lighting that Strike to the land of Venus surface. There temperature is around 800 dergree that is 10x tempearutre what were use to earth. No wonder why Venus it is very darngeous not able many people could not survice.\n",
      "\n",
      "In the Article\n",
      "\n",
      "\"The Challenge Exploring Venus\" reperoted\n",
      "\n",
      "Venus was not always a dangerous planet becuase long time it use to be earth life. Example the rocky surface some Feature are include what we have life on eath. Valley and Mountains it make scientists want to go back to study in venus. NASA are coming up with some ways Scientist can go study in Venus. Then we can know more about the planet. One day Venus might go back to earth life won't be as dangerous.\n",
      "\n",
      "In the Article \"The Challenge Exploring Venus NASA\"reproted NASA is caming with intvend For Studying In Venus. One is Vechile above 30 mile above surface It would help by not staying on the groud because the bad effect it had. The temperature would be close to earth level won't be easy but human would be able to survice. But also ned to get close to the planet even know that risk their going to take. inculding their going to be a machine allow know about Venus. The machine were made in 1940 in world war 2 were very imprortant. By using the Machine the tin wold not be able to melt.\n",
      "\n",
      "Conclusion: Even through Venus is very dareous planet to Study. Those people should just take the risk to Study at venus. NASA is coming up with many ways to keep the people safte. Maybe one day Venus can go back to earth lice    \n",
      "- assignment: In \"The Challenge of Exploring Venus,\" the author suggests studying Venus is a worthy pursuit despite the dangers it presents. Using details from the article, write an essay evaluating how well the author supports this idea. Be sure to include: a claim that evaluates how well the author supports the idea that studying Venus is a worthy pursuit despite the dangers; an explanation of the evidence from the article that supports your claim; an introduction, a body, and a conclusion to your essay.\n",
      "- prompt_name: Exploring Venus\n",
      "- economically_disadvantaged: Economically disadvantaged\n",
      "- student_disability_status: Identified as having disability\n",
      "- ell_status: Yes\n",
      "- race_ethnicity: Hispanic/Latino\n",
      "- gender: F\n",
      "- source_text_1: The Challenge of Exploring Venus\n",
      "Venus, sometimes called the “Evening Star,” is one of the brightest points of light in the night sky, making it simple for even and amateur stargazer to spot. However, this nickname is misleading since Venus is actually a planet. While Venus is simple to see from the distant but safe vantage point of Earth, it has proved a very challenging place to examine more closely. \n",
      "Often referred to as Earth's “twin,” Venus is the closest planet to Earth in terms of density and size, and occasionally the closest in distance too. Earth, Venus, and Mars, our other planetary neighbor, orbit the sun at different speeds. These differences in speed mean that sometimes we are closer to Mars and other times to Venus. Because Venus is sometimes right around the corner - in space terms - humans have spent numerous spacecraft to land on this cloud-draped world. Each previous mission was unmanned, and for good reason, since no spacecraft survived the landing for more than a few hours. Maybe this issue explains why not a single spaceship has touched down of Venus in more than three decades. Numberous factors contribute to Venus's reputation as a challenging planet for humans to study, despite its proximity to us. \n",
      "A thick atmosphere of almost 97 percent carbon dioxide blankets Venus. Even more challenging are the clouds of highly corrosive sulfuric acid in Venus's atmosphere. On the planet's surface, temperatures average over 800 degrees Fahrenheit, and the atmospheric pressure is 90 times greater than what we experience on our own planet. These conditions are far more extreme than anything humans encounter on Earth; such an environment would crush even a submarine accustomed to diving to the deepest parts of our oceans and would liquefy many metals. Also notable, Venus has the hottest surface temperature of any planet in our solar system, even though Mercury is closer to our sun. Beyond high presure and heat, Venusian geology and weather present additional impediments like erupting volcanoes, powerful earthquakes, and frequent lightning strikes to probes seeking to land on its surface. \n",
      "If our sister is so inhospitable, why are scientists even discussing further visits to its surface? Astronomers are fascinated by Venus beccause it may well once have been the most Earth-like planet in our solar system. Long ago, Venus was probably covered largely with oceans and could have supported various forms of life, just like Earth. Today, Venus still has some features that are analogous to those on Earth. The planet has a surface of rocky sediment and includes familiar features such as valleys, mountains, and craters. Furthermore, recall that Venus can sometimes be our nearest option for a planetary visit, a crucial consideration given the long time frames of space travel. The value of returning to Venus seems indisputable, but what are the options for making such a mission both safe and scientifically productive?\n",
      "The National Aeronautics and Space Administration (NASA) has one particularly compelling idea for sending humans to study Venus. NASA's possible solution to the hostile conditions on the surface of Venus would allow scientists to float above the fray. Imagine a blimp-like vehicle hovering 30 or so miles above the roiling Venusian landscape. Just as our jet airplanes travel at a higher altitude to fly over many storms, a vehicle hovering over Venus would avoid the unfriendly ground conditions by staying up and out of their way. At thirty-plus miles above the surface, temperatures would still be toasty at around 170 degrees Farenheit, but the air pressure would be close to that of sea level on Earth. Solar power would be plentiful, and radiation would not exceed Earth levels. Not easy conditions, but survivable for humans.\n",
      "However, peering at Venus from a ship orbiting or hovering safely far above the planet can provide only limited insight on ground conditions rendering standard forms of photography and videography ineffective. More importantly, researchers cannot take samples of rock, gas, or anything else, from a distance. Therefore, scientists seeking to conduct a thorough mission to understand Venus would need to get up close and personal despite the risks. Or maybe we should think of them as challenges. Many researchers are working on innovattions that would allow our machines to last long enough to contribute meaningfully to our knowledge of Venus. \n",
      "NASA is working on other approaches to studying Venus. For example, some simplified electronics made of silicon carbide have been tested in a chamber simuulating the chaos of Venus's surface and have laster for three weeks in such conditions. Another project is looking back to an old technology called mechanical computers. These devices were first envisioned in the 1800s and played an important role int he 1940s during World War II. The thought of computers existing in those days may sound shocking, but these devices make calculations by using gears and levers and do not require electronics at all. Modern commputers are enormously powerful, flexible, and quick, but tend to be more delicate when it comes to extreme physical conditions. Just imagine exposing a cell phone or tablet to acid or heat capable of melting tin. By comparison, systems that use mechanical parts can be made mroe resistant to pressure, heat, and other forces. \n",
      "Striving to meet the challenge presented by Venus has value, not only because of the insight to be gained on the planet itself, but also because human curiousity will likely lead us into many equally intimidating endeavors. Our travels on Earth and beyond should not be limited by dangers and doubts but should be expanded to meet the very edges of imagination and innovation.\n",
      "- source_text_2: nan\n",
      "- source_text_3: nan\n",
      "- source_text_4: nan\n"
     ]
    }
   ],
   "source": [
    "for col_name, value in asap2_df.iloc[100].items():\n",
    "    print(f\"- {col_name}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12978, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asap_file = r\"C:\\Users\\alvar\\Githubs\\mentor-eval\\datasets\\asap-aes\\training_set_rel3.xlsx\"\n",
    "df = pd.read_excel(asap_file)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>rater1_trait1</th>\n",
       "      <th>rater1_trait2</th>\n",
       "      <th>rater1_trait3</th>\n",
       "      <th>rater1_trait4</th>\n",
       "      <th>rater1_trait5</th>\n",
       "      <th>rater1_trait6</th>\n",
       "      <th>rater2_trait1</th>\n",
       "      <th>rater2_trait2</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0             4.0             4.0             NaN            8.0   \n",
       "1             5.0             4.0             NaN            9.0   \n",
       "2             4.0             3.0             NaN            7.0   \n",
       "3             5.0             5.0             NaN           10.0   \n",
       "4             4.0             4.0             NaN            8.0   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  rater1_trait1  \\\n",
       "0             NaN             NaN            NaN            NaN   \n",
       "1             NaN             NaN            NaN            NaN   \n",
       "2             NaN             NaN            NaN            NaN   \n",
       "3             NaN             NaN            NaN            NaN   \n",
       "4             NaN             NaN            NaN            NaN   \n",
       "\n",
       "   rater1_trait2  rater1_trait3  rater1_trait4  rater1_trait5  rater1_trait6  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater2_trait1  rater2_trait2  rater2_trait3  rater2_trait4  rater2_trait5  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater2_trait6  rater3_trait1  rater3_trait2  rater3_trait3  rater3_trait4  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN  \n",
       "1            NaN            NaN  \n",
       "2            NaN            NaN  \n",
       "3            NaN            NaN  \n",
       "4            NaN            NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>rater1_trait1</th>\n",
       "      <th>rater1_trait2</th>\n",
       "      <th>rater1_trait3</th>\n",
       "      <th>rater1_trait4</th>\n",
       "      <th>rater1_trait5</th>\n",
       "      <th>rater1_trait6</th>\n",
       "      <th>rater2_trait1</th>\n",
       "      <th>rater2_trait2</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>4175</td>\n",
       "      <td>2</td>\n",
       "      <td>Libraries            @CAPS1 are many libraries...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>4176</td>\n",
       "      <td>2</td>\n",
       "      <td>Good? Bad? Offensive or not? These are just a ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>4177</td>\n",
       "      <td>2</td>\n",
       "      <td>When it comes to the decision of certain mater...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>4178</td>\n",
       "      <td>2</td>\n",
       "      <td>I think that the music and other things beside...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>4179</td>\n",
       "      <td>2</td>\n",
       "      <td>In my opinion, I do believe we should not have...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  essay_set                                              essay  \\\n",
       "2980      4175          2  Libraries            @CAPS1 are many libraries...   \n",
       "2981      4176          2  Good? Bad? Offensive or not? These are just a ...   \n",
       "2982      4177          2  When it comes to the decision of certain mater...   \n",
       "2983      4178          2  I think that the music and other things beside...   \n",
       "2984      4179          2  In my opinion, I do believe we should not have...   \n",
       "\n",
       "      rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "2980             3.0             3.0             NaN            3.0   \n",
       "2981             5.0             5.0             NaN            5.0   \n",
       "2982             4.0             4.0             NaN            4.0   \n",
       "2983             4.0             3.0             NaN            4.0   \n",
       "2984             3.0             3.0             NaN            3.0   \n",
       "\n",
       "      rater1_domain2  rater2_domain2  domain2_score  rater1_trait1  \\\n",
       "2980             3.0             3.0            3.0            NaN   \n",
       "2981             4.0             4.0            4.0            NaN   \n",
       "2982             4.0             4.0            4.0            NaN   \n",
       "2983             3.0             2.0            3.0            NaN   \n",
       "2984             4.0             4.0            4.0            NaN   \n",
       "\n",
       "      rater1_trait2  rater1_trait3  rater1_trait4  rater1_trait5  \\\n",
       "2980            NaN            NaN            NaN            NaN   \n",
       "2981            NaN            NaN            NaN            NaN   \n",
       "2982            NaN            NaN            NaN            NaN   \n",
       "2983            NaN            NaN            NaN            NaN   \n",
       "2984            NaN            NaN            NaN            NaN   \n",
       "\n",
       "      rater1_trait6  rater2_trait1  rater2_trait2  rater2_trait3  \\\n",
       "2980            NaN            NaN            NaN            NaN   \n",
       "2981            NaN            NaN            NaN            NaN   \n",
       "2982            NaN            NaN            NaN            NaN   \n",
       "2983            NaN            NaN            NaN            NaN   \n",
       "2984            NaN            NaN            NaN            NaN   \n",
       "\n",
       "      rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  \\\n",
       "2980            NaN            NaN            NaN            NaN   \n",
       "2981            NaN            NaN            NaN            NaN   \n",
       "2982            NaN            NaN            NaN            NaN   \n",
       "2983            NaN            NaN            NaN            NaN   \n",
       "2984            NaN            NaN            NaN            NaN   \n",
       "\n",
       "      rater3_trait2  rater3_trait3  rater3_trait4  rater3_trait5  \\\n",
       "2980            NaN            NaN            NaN            NaN   \n",
       "2981            NaN            NaN            NaN            NaN   \n",
       "2982            NaN            NaN            NaN            NaN   \n",
       "2983            NaN            NaN            NaN            NaN   \n",
       "2984            NaN            NaN            NaN            NaN   \n",
       "\n",
       "      rater3_trait6  \n",
       "2980            NaN  \n",
       "2981            NaN  \n",
       "2982            NaN  \n",
       "2983            NaN  \n",
       "2984            NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2980:2985].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Essay Set 1:\n",
      "--------------------------------------------------\n",
      "essay_id:\n",
      "  Min: 1\n",
      "  Max: 1787\n",
      "essay_set:\n",
      "  Min: 1\n",
      "  Max: 1\n",
      "rater1_domain1:\n",
      "  Min: 1.0\n",
      "  Max: 6.0\n",
      "rater2_domain1:\n",
      "  Min: 1.0\n",
      "  Max: 6.0\n",
      "rater3_domain1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "domain1_score:\n",
      "  Min: 2.0\n",
      "  Max: 12.0\n",
      "rater1_domain2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_domain2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "domain2_score:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "\n",
      "Percentage where domain1_score matches sum of rater scores: 100.00%\n",
      "\n",
      "Essay Set 2:\n",
      "--------------------------------------------------\n",
      "essay_id:\n",
      "  Min: 2978\n",
      "  Max: 4777\n",
      "essay_set:\n",
      "  Min: 2\n",
      "  Max: 2\n",
      "rater1_domain1:\n",
      "  Min: 1.0\n",
      "  Max: 6.0\n",
      "rater2_domain1:\n",
      "  Min: 1.0\n",
      "  Max: 6.0\n",
      "rater3_domain1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "domain1_score:\n",
      "  Min: 1.0\n",
      "  Max: 6.0\n",
      "rater1_domain2:\n",
      "  Min: 1.0\n",
      "  Max: 4.0\n",
      "rater2_domain2:\n",
      "  Min: 1.0\n",
      "  Max: 4.0\n",
      "domain2_score:\n",
      "  Min: 1.0\n",
      "  Max: 4.0\n",
      "rater1_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "\n",
      "Percentage where domain1_score matches average of rater scores: 78.33%\n",
      "\n",
      "Percentage where domain2_score matches average of rater scores: 79.67%\n",
      "\n",
      "Essay Set 3:\n",
      "--------------------------------------------------\n",
      "essay_id:\n",
      "  Min: 5978\n",
      "  Max: 7708\n",
      "essay_set:\n",
      "  Min: 3\n",
      "  Max: 3\n",
      "rater1_domain1:\n",
      "  Min: 0.0\n",
      "  Max: 3.0\n",
      "rater2_domain1:\n",
      "  Min: 0.0\n",
      "  Max: 3.0\n",
      "rater3_domain1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "domain1_score:\n",
      "  Min: 0.0\n",
      "  Max: 3.0\n",
      "rater1_domain2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_domain2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "domain2_score:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "\n",
      "Percentage where domain1_score matches average of rater scores: 74.86%\n",
      "\n",
      "Essay Set 4:\n",
      "--------------------------------------------------\n",
      "essay_id:\n",
      "  Min: 8863\n",
      "  Max: 10642\n",
      "essay_set:\n",
      "  Min: 4\n",
      "  Max: 4\n",
      "rater1_domain1:\n",
      "  Min: 0.0\n",
      "  Max: 3.0\n",
      "rater2_domain1:\n",
      "  Min: 0.0\n",
      "  Max: 3.0\n",
      "rater3_domain1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "domain1_score:\n",
      "  Min: 0.0\n",
      "  Max: 3.0\n",
      "rater1_domain2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_domain2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "domain2_score:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "\n",
      "Percentage where domain1_score matches average of rater scores: 77.20%\n",
      "\n",
      "Essay Set 5:\n",
      "--------------------------------------------------\n",
      "essay_id:\n",
      "  Min: 11827\n",
      "  Max: 13631\n",
      "essay_set:\n",
      "  Min: 5\n",
      "  Max: 5\n",
      "rater1_domain1:\n",
      "  Min: 0.0\n",
      "  Max: 4.0\n",
      "rater2_domain1:\n",
      "  Min: 0.0\n",
      "  Max: 4.0\n",
      "rater3_domain1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "domain1_score:\n",
      "  Min: 0.0\n",
      "  Max: 4.0\n",
      "rater1_domain2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_domain2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "domain2_score:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "\n",
      "Percentage where domain1_score matches average of rater scores: 59.06%\n",
      "\n",
      "Essay Set 6:\n",
      "--------------------------------------------------\n",
      "essay_id:\n",
      "  Min: 14834\n",
      "  Max: 16633\n",
      "essay_set:\n",
      "  Min: 6\n",
      "  Max: 6\n",
      "rater1_domain1:\n",
      "  Min: 0.0\n",
      "  Max: 4.0\n",
      "rater2_domain1:\n",
      "  Min: 0.0\n",
      "  Max: 4.0\n",
      "rater3_domain1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "domain1_score:\n",
      "  Min: 0.0\n",
      "  Max: 4.0\n",
      "rater1_domain2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_domain2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "domain2_score:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "\n",
      "Percentage where domain1_score matches average of rater scores: 62.44%\n",
      "\n",
      "Essay Set 7:\n",
      "--------------------------------------------------\n",
      "essay_id:\n",
      "  Min: 17834\n",
      "  Max: 19563\n",
      "essay_set:\n",
      "  Min: 7\n",
      "  Max: 7\n",
      "rater1_domain1:\n",
      "  Min: 0.0\n",
      "  Max: 12.0\n",
      "rater2_domain1:\n",
      "  Min: 0.0\n",
      "  Max: 12.0\n",
      "rater3_domain1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "domain1_score:\n",
      "  Min: 2.0\n",
      "  Max: 24.0\n",
      "rater1_domain2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_domain2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "domain2_score:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait1:\n",
      "  Min: 0.0\n",
      "  Max: 3.0\n",
      "rater1_trait2:\n",
      "  Min: 0.0\n",
      "  Max: 3.0\n",
      "rater1_trait3:\n",
      "  Min: 0.0\n",
      "  Max: 3.0\n",
      "rater1_trait4:\n",
      "  Min: 0.0\n",
      "  Max: 3.0\n",
      "rater1_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait1:\n",
      "  Min: 0.0\n",
      "  Max: 3.0\n",
      "rater2_trait2:\n",
      "  Min: 0.0\n",
      "  Max: 3.0\n",
      "rater2_trait3:\n",
      "  Min: 0.0\n",
      "  Max: 3.0\n",
      "rater2_trait4:\n",
      "  Min: 0.0\n",
      "  Max: 3.0\n",
      "rater2_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait1:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait3:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait4:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait5:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater3_trait6:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "\n",
      "Percentage where domain1_score matches average of rater scores: 0.00%\n",
      "\n",
      "Essay Set 8:\n",
      "--------------------------------------------------\n",
      "essay_id:\n",
      "  Min: 20716\n",
      "  Max: 21633\n",
      "essay_set:\n",
      "  Min: 8\n",
      "  Max: 8\n",
      "rater1_domain1:\n",
      "  Min: 5.0\n",
      "  Max: 30.0\n",
      "rater2_domain1:\n",
      "  Min: 5.0\n",
      "  Max: 30.0\n",
      "rater3_domain1:\n",
      "  Min: 20.0\n",
      "  Max: 50.0\n",
      "domain1_score:\n",
      "  Min: 10.0\n",
      "  Max: 60.0\n",
      "rater1_domain2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater2_domain2:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "domain2_score:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "rater1_trait1:\n",
      "  Min: 1.0\n",
      "  Max: 6.0\n",
      "rater1_trait2:\n",
      "  Min: 1.0\n",
      "  Max: 6.0\n",
      "rater1_trait3:\n",
      "  Min: 1.0\n",
      "  Max: 6.0\n",
      "rater1_trait4:\n",
      "  Min: 1.0\n",
      "  Max: 6.0\n",
      "rater1_trait5:\n",
      "  Min: 1.0\n",
      "  Max: 6.0\n",
      "rater1_trait6:\n",
      "  Min: 1.0\n",
      "  Max: 6.0\n",
      "rater2_trait1:\n",
      "  Min: 1.0\n",
      "  Max: 6.0\n",
      "rater2_trait2:\n",
      "  Min: 1.0\n",
      "  Max: 6.0\n",
      "rater2_trait3:\n",
      "  Min: 1.0\n",
      "  Max: 6.0\n",
      "rater2_trait4:\n",
      "  Min: 1.0\n",
      "  Max: 6.0\n",
      "rater2_trait5:\n",
      "  Min: 1.0\n",
      "  Max: 6.0\n",
      "rater2_trait6:\n",
      "  Min: 1.0\n",
      "  Max: 6.0\n",
      "rater3_trait1:\n",
      "  Min: 2.0\n",
      "  Max: 6.0\n",
      "rater3_trait2:\n",
      "  Min: 2.0\n",
      "  Max: 6.0\n",
      "rater3_trait3:\n",
      "  Min: 2.0\n",
      "  Max: 6.0\n",
      "rater3_trait4:\n",
      "  Min: 3.0\n",
      "  Max: 6.0\n",
      "rater3_trait5:\n",
      "  Min: 2.0\n",
      "  Max: 5.0\n",
      "rater3_trait6:\n",
      "  Min: 2.0\n",
      "  Max: 5.0\n",
      "\n",
      "Percentage where domain1_score matches average of rater scores: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store dataframes by essay_set\n",
    "essay_sets = {}\n",
    "\n",
    "# Split the dataframe by essay_set\n",
    "for set_id in df['essay_set'].unique():\n",
    "    essay_sets[set_id] = df[df['essay_set'] == set_id]\n",
    "\n",
    "# For each essay set, print min and max of numeric columns\n",
    "for set_id, set_df in essay_sets.items():\n",
    "    print(f\"\\nEssay Set {set_id}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Get numeric columns\n",
    "    numeric_cols = set_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    \n",
    "    # Print min and max for each numeric column\n",
    "    for col in numeric_cols:\n",
    "        print(f\"{col}:\")\n",
    "        print(f\"  Min: {set_df[col].min()}\")\n",
    "        print(f\"  Max: {set_df[col].max()}\")\n",
    "    \n",
    "    # Check all domain scores against their corresponding rater scores\n",
    "    domain_cols = [col for col in set_df.columns if col.startswith('domain') and col.endswith('_score')]\n",
    "    \n",
    "    for domain_col in domain_cols:\n",
    "        domain_num = domain_col.replace('domain', '').replace('_score', '')\n",
    "        rater_cols = [col for col in set_df.columns if col.startswith(f'rater') and f'domain{domain_num}' in col]\n",
    "        \n",
    "        # Only check if we have both domain score and at least one rater\n",
    "        if domain_col in set_df.columns and rater_cols:\n",
    "            # Get non-null domain scores\n",
    "            valid_scores = set_df[domain_col].notna()\n",
    "            \n",
    "            if valid_scores.any():\n",
    "                if set_id == 1:\n",
    "                    # For essay set 1, sum all non-null rater scores\n",
    "                    total_raters = set_df[rater_cols].sum(axis=1)\n",
    "                    matches = (set_df[domain_col] == total_raters).mean() * 100\n",
    "                    print(f\"\\nPercentage where {domain_col} matches sum of rater scores: {matches:.2f}%\")\n",
    "                else:\n",
    "                    # For other essay sets, calculate average of rater scores\n",
    "                    avg_raters = set_df[rater_cols].mean(axis=1)\n",
    "                    matches = (set_df[domain_col] == avg_raters).mean() * 100\n",
    "                    print(f\"\\nPercentage where {domain_col} matches average of rater scores: {matches:.2f}%\")\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Essay Set #1--ReadMeFirst.docx to txt\n",
      "Converted Essay Set #2--ReadMeFirst.docx to txt\n",
      "Converted Essay Set #3--ReadMeFirst.docx to txt\n",
      "Converted Essay Set #4--ReadMeFirst.docx to txt\n",
      "Converted Essay Set #5--ReadMeFirst.docx to txt\n",
      "Converted Essay Set #6--ReadMeFirst.docx to txt\n",
      "Converted Essay Set #7--ReadMeFirst.docx to txt\n",
      "Converted Essay Set #8--ReadMeFirst.docx to txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from docx2txt import process\n",
    "\n",
    "# Path to the folder containing docx files\n",
    "folder_path = r\"C:\\Users\\alvar\\Githubs\\mentor-eval\\datasets\\asap-aes\\Essay_Set_Descriptions\"\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "output_folder = os.path.join(folder_path, \"txt_output\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Convert each docx file to txt\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".docx\"):\n",
    "        # Get full file paths\n",
    "        docx_path = os.path.join(folder_path, filename)\n",
    "        txt_path = os.path.join(output_folder, filename.replace(\".docx\", \".txt\"))\n",
    "        \n",
    "        # Convert docx to text\n",
    "        text = process(docx_path)\n",
    "        \n",
    "        # Save text to file\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(text)\n",
    "            \n",
    "        print(f\"Converted {filename} to txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mentor-eval-datasets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
